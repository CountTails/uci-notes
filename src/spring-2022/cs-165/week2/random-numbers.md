# Random numbers

## Random number sequences

### Definition

- Each element is chosen independently (does not follow) from a probability distribution
- Randomness of a sequence is the Kolmogorav complexity of the sequence
    - An infinite sequence should require infinite sized Turing machine
    - There is no computational way to express the sequence

### Sources of randomness

- Radioactive decay
- Radio frequency noise
- Noise generated by a resistor or diode
- Inter-keyboard timings
- Inter-interrupt timings

#### Combining sources

- Suppose the $r_{1}$, $r_{2}$, $\dots$ , $r_{k}$ are random numbers from different sources
- $b = r_{1} \oplus r_{2} \oplus \dots \oplus r_{k}$
- If any one of $r_{1}$, $r_{2}$, $\dots$ , $r_{k}$ is truly random, then so is $b$

#### Skew correction

- Von Neumann's algorithm: converts biased random bits to unbiased random bits
    1) Collect two random bits
    2) Discard if they are identical
    3) Otherwise, use the first bit
- Input may be biased, but output is unbiased

## Testing randomness

### Chi square test

- Consider an experiment with $k$ outcomes, performed $n$ times
- $p_{1},\, \dots ,\, p_{k}$ denote the probability of each outcome
- $Y_{1},\, \dots ,\, Y_{k}$ denote the number of times each outcome occurred

$$
    X^{2} = \sum \limits_{1 \le s \le k} \frac{(Y_{s} - np_{s})^{2}}{np_{s}}
$$

- We want the top term to be small and the bottom term to be smaller
- A large $X^{2}$ indicates deviance from random chance
- A small $X^{2}$ indicates closer to random chance

### Analysis of random.org

- Entropy = 7.999805 bits per character
- Optimum compression would reduce the size of this 1048576 character file by 0%
- Chi square distribution for 1948576 samples is 283.61, and randomly would exceed this value 25% of the times
- Arithmetic mean value of data bytes is 127.46 (127.5 = random)

### Analysis of a JPEG file

- Entropy = 7.980627 bits per character
- Optimum compression would reduce the size of this 51768 character file by 0%
- Chi square distribution for 51768 samples is 1542.24, and randomly would exceed this value 0.01% of the times
- Arithmetic mean value of data bytes is 125.93 (127.5 = random)

## Pseudorandom number generators

- A pseudorandom number generator (PRNG) is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers
- The PRNG-generated sequence is not truly random, because it is completely determined by an initial value, called the PRNG seed
- Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed and reproducibility
- PRNGs are central to applications such as simulations, electronic games, and cryptography
- Cryptographic applications require the output not to be predictable from earlier outputs

### Linear congruential generators

- Choose two prime numbers $P_{1}$ and $P_{2}$
- $x_{0}$ is given (seed value)
- $x_{n + 1} = P_{1}x_{n} + P_{2} \mod N$
- Quite easy to implement, used everywhere

### Cryptographically strong number generators

- Next-bit test: given a sequence of bits $x_{1},\, x_{2},\, \dots,\, x_{k}$, there is no polynomial time algorithm to generate $x_{k+1}$
- A sequence that passes the next-bit test passes all other polynomial-time statistical tests for randomness